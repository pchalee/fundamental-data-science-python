{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hosting Model using API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Python Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"titanic-train.csv\")\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch\n",
       "0         0       3    male  22.0      1      0\n",
       "1         1       1  female  38.0      1      0\n",
       "2         1       3  female  26.0      0      0\n",
       "3         1       1  female  35.0      1      0\n",
       "4         0       3    male  35.0      0      0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.loc[:,['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch']]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age missing  177\n",
      "PClass missing  0\n",
      "SibSp missing  0\n",
      "Parch missing  0\n",
      "Survived missing  0\n"
     ]
    }
   ],
   "source": [
    "print('Age missing ', df2['Age'].isnull().sum())\n",
    "print('PClass missing ', df2['Pclass'].isnull().sum())\n",
    "print('SibSp missing ', df2['SibSp'].isnull().sum())\n",
    "print('Parch missing ', df2['Parch'].isnull().sum())\n",
    "print('Survived missing ', df2['Survived'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age missing  0\n"
     ]
    }
   ],
   "source": [
    "df2['Age'] = df2['Age'].fillna(df2['Age'].mean())\n",
    "\n",
    "print('Age missing ', df2['Age'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch'], dtype='object')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch  Sex_female  Sex_male\n",
       "0         0       3  22.0      1      0           0         1\n",
       "1         1       1  38.0      1      0           1         0\n",
       "2         1       3  26.0      0      0           1         0\n",
       "3         1       1  35.0      1      0           1         0\n",
       "4         0       3  35.0      0      0           0         1"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.get_dummies(df2)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels for training and testing data\n",
      "     Pclass  Sex_male  Sex_female        Age  SibSp  Parch\n",
      "199       2         0           1  24.000000      0      0\n",
      "468       3         1           0  29.699118      0      0\n",
      "198       3         0           1  29.699118      0      0\n",
      "574       3         1           0  16.000000      0      0\n",
      "776       3         1           0  29.699118      0      0\n",
      "148       2         1           0  36.500000      0      2\n",
      "227       3         1           0  20.500000      0      0\n",
      "408       3         1           0  21.000000      0      0\n",
      "762       3         1           0  20.000000      0      0\n",
      "166       1         0           1  29.699118      0      1\n",
      "62        1         1           0  45.000000      1      0\n",
      "427       2         0           1  19.000000      0      0\n",
      "662       1         1           0  47.000000      0      0\n",
      "471       3         1           0  38.000000      0      0\n",
      "732       2         1           0  29.699118      0      0\n",
      "610       3         0           1  39.000000      1      5\n",
      "157       3         1           0  30.000000      0      0\n",
      "499       3         1           0  24.000000      0      0\n",
      "370       1         1           0  25.000000      1      0\n",
      "295       1         1           0  29.699118      0      0\n",
      "837       3         1           0  29.699118      0      0\n",
      "484       1         1           0  25.000000      1      0\n",
      "258       1         0           1  35.000000      0      0\n",
      "567       3         0           1  29.000000      0      4\n",
      "856       1         0           1  45.000000      1      1\n",
      "871       1         0           1  47.000000      1      1\n",
      "290       1         0           1  26.000000      0      0\n",
      "782       1         1           0  29.000000      0      0\n",
      "411       3         1           0  29.699118      0      0\n",
      "220       3         1           0  16.000000      0      0\n",
      "..      ...       ...         ...        ...    ...    ...\n",
      "501       3         0           1  21.000000      0      0\n",
      "526       2         0           1  50.000000      0      0\n",
      "51        3         1           0  21.000000      0      0\n",
      "282       3         1           0  16.000000      0      0\n",
      "796       1         0           1  49.000000      0      0\n",
      "557       1         1           0  29.699118      0      0\n",
      "110       1         1           0  47.000000      0      0\n",
      "698       1         1           0  49.000000      1      1\n",
      "281       3         1           0  28.000000      0      0\n",
      "731       3         1           0  11.000000      0      0\n",
      "679       1         1           0  36.000000      0      1\n",
      "658       2         1           0  23.000000      0      0\n",
      "663       3         1           0  36.000000      0      0\n",
      "459       3         1           0  29.699118      0      0\n",
      "381       3         0           1   1.000000      0      2\n",
      "865       2         0           1  42.000000      0      0\n",
      "486       1         0           1  35.000000      1      0\n",
      "890       3         1           0  32.000000      0      0\n",
      "378       3         1           0  20.000000      0      0\n",
      "697       3         0           1  29.699118      0      0\n",
      "332       1         1           0  38.000000      0      1\n",
      "0         3         1           0  22.000000      1      0\n",
      "534       3         0           1  30.000000      0      0\n",
      "823       3         0           1  27.000000      0      1\n",
      "209       1         1           0  40.000000      0      0\n",
      "737       1         1           0  35.000000      0      0\n",
      "360       3         1           0  40.000000      1      4\n",
      "669       1         0           1  29.699118      1      0\n",
      "245       1         1           0  44.000000      2      0\n",
      "768       3         1           0  29.699118      1      0\n",
      "\n",
      "[623 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kris/anaconda3/anaconda/envs/softwarepark/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(df3[['Pclass','Sex_male','Sex_female','Age','SibSp','Parch']], \n",
    "                                                    df3['Survived'], \n",
    "                                                    train_size=0.7,\n",
    "                                                    stratify=df3['Survived'].values,\n",
    "                                                    random_state=123)\n",
    "print(\"Labels for training and testing data\")\n",
    "print(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training :  [61.63723917 38.36276083]\n",
      "Testing :  [61.56716418 38.43283582]\n"
     ]
    }
   ],
   "source": [
    "print('Training : ', np.bincount(train_y) / float(len(train_y)) * 100.0)\n",
    "print('Testing : ', np.bincount(test_y) / float(len(test_y)) * 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
       "            oob_score=True, random_state=1234, verbose=True,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a random forest Classifier. By convention, clf means 'Classifier'\n",
    "clf = RandomForestClassifier(n_estimators=500, oob_score=True, max_depth=5,\n",
    "                             criterion='entropy', random_state=1234,\n",
    "                             verbose=True, n_jobs=-1)\n",
    "\n",
    "# Train the Classifier to take the training features and learn how they relate\n",
    "# to the training y (the species)\n",
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8426966292134831"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.826645264847512"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Titanic on the train set using Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurary :  0.8427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       384\n",
      "           1       0.83      0.74      0.78       239\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       623\n",
      "   macro avg       0.84      0.82      0.83       623\n",
      "weighted avg       0.84      0.84      0.84       623\n",
      "\n",
      "[[348  36]\n",
      " [ 62 177]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Predicting Titanic on the train set using Random Forest\")\n",
    "\n",
    "y_train_pred = clf.predict(train_X)\n",
    "\n",
    "print(\"Accurary : \", round(accuracy_score(train_y, y_train_pred),4))\n",
    "print(classification_report(train_y, y_train_pred))\n",
    "print(confusion_matrix(train_y, y_train_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Titanic on the test set using Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurary :  0.8209\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86       165\n",
      "           1       0.82      0.68      0.74       103\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       268\n",
      "   macro avg       0.82      0.79      0.80       268\n",
      "weighted avg       0.82      0.82      0.82       268\n",
      "\n",
      "[[150  15]\n",
      " [ 33  70]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting Titanic on the test set using Random Forest\")\n",
    "\n",
    "y_pred = clf.predict(test_X)\n",
    "\n",
    "print(\"Accurary : \", round(accuracy_score(test_y, y_pred),4))\n",
    "print(classification_report(test_y, y_pred))\n",
    "print(confusion_matrix(test_y, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dumped!\n",
      "Models columns dumped!\n"
     ]
    }
   ],
   "source": [
    "# Save your model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf, 'model.pkl')\n",
    "print(\"Model dumped!\")\n",
    "\n",
    "\n",
    "# Saving the data columns from training\n",
    "model_columns = list(df3.columns)\n",
    "joblib.dump(model_columns, 'model_columns.pkl')\n",
    "print(\"Models columns dumped!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model that you just saved\n",
    "lr = joblib.load('model.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Titanic on the test set using Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurary :  0.8209\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86       165\n",
      "           1       0.82      0.68      0.74       103\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       268\n",
      "   macro avg       0.82      0.79      0.80       268\n",
      "weighted avg       0.82      0.82      0.82       268\n",
      "\n",
      "[[150  15]\n",
      " [ 33  70]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting Titanic on the test set using Random Forest\")\n",
    "\n",
    "y_pred = lr.predict(test_X)\n",
    "\n",
    "print(\"Accurary : \", round(accuracy_score(test_y, y_pred),4))\n",
    "print(classification_report(test_y, y_pred))\n",
    "print(confusion_matrix(test_y, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
